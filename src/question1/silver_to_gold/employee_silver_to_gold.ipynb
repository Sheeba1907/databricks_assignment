{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f77a8eb8-8726-43c0-a266-cf1c556de883",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"/Workspace/Users/sheeba.banu@diggibyte.com/databricks_assignment/src/question1/source_to_bronze/utils\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67c41230-8d7f-4896-a613-921c6180352a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Read silver table\n",
    "employee_df = spark.read.table(\"workspace.employee_info.dim_employee\")\n",
    "\n",
    "# 1️⃣ Salary of each department in descending order\n",
    "dept_salary_df = (\n",
    "    employee_df.groupBy(\"department_id\")\n",
    "               .agg(F.sum(\"salary\").alias(\"total_salary\"))\n",
    "               .orderBy(F.desc(\"total_salary\"))\n",
    ")\n",
    "\n",
    "# 2️⃣ Number of employees in each department per country\n",
    "dept_country_count_df = (\n",
    "    employee_df.groupBy(\"department_id\", \"country_id\")\n",
    "               .agg(F.count(\"employee_id\").alias(\"employee_count\"))\n",
    ")\n",
    "\n",
    "# 3️⃣ Department names along with country names\n",
    "# (Assuming you have department & country reference data, else skip)\n",
    "department_df = spark.read.csv(\"/Volumes/assignment/default/write_path/department/\", header=True)\n",
    "country_df = spark.read.csv(\"/Volumes/assignment/default/write_path/country/\", header=True)\n",
    "dept_country_df = (\n",
    "    employee_df.join(department_df, employee_df[\"department_id\"] == department_df[\"DepartmentID\"],\"inner\")\n",
    "    .join(country_df, employee_df[\"country_id\"] == country_df[\"CountryCode\"], \"inner\")\n",
    "                 .select(\"department_id\", \"country_id\")\n",
    "                 .withColumn(\"at_load_date\", F.current_date())\n",
    ")\n",
    "\n",
    "# 4️⃣ Average age of employees in each department\n",
    "avg_age_df = (\n",
    "    employee_df.groupBy(\"department_id\")\n",
    "               .agg(F.avg(\"age\").alias(\"avg_age\"))\n",
    ")\n",
    "\n",
    "# Add load date\n",
    "dept_salary_df = add_load_date(dept_salary_df, \"at_load_date\")\n",
    "dept_country_count_df = add_load_date(dept_country_count_df, \"at_load_date\")\n",
    "avg_age_df = add_load_date(avg_age_df, \"at_load_date\")\n",
    "\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS assignment.gold\")\n",
    "\n",
    "# Write Gold outputs with overwrite + replaceWhere\n",
    "gold_schema = \"assignment.gold\"\n",
    "\n",
    "(\n",
    "    dept_salary_df.write.format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"replaceWhere\", \"at_load_date = current_date()\")\n",
    "    .saveAsTable(f\"{gold_schema}.fact_dept_salary\")\n",
    ")\n",
    "\n",
    "(\n",
    "    dept_country_count_df.write.format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"replaceWhere\", \"at_load_date = current_date()\")\n",
    "    .saveAsTable(f\"{gold_schema}.fact_dept_country_count\")\n",
    ")\n",
    "\n",
    "(\n",
    "    dept_country_df.write.format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"replaceWhere\", \"at_load_date = current_date()\")\n",
    "    .saveAsTable(f\"{gold_schema}.fact_department_country\")\n",
    ")\n",
    "\n",
    "(\n",
    "    avg_age_df.write.format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"replaceWhere\", \"at_load_date = current_date()\")\n",
    "    .saveAsTable(f\"{gold_schema}.fact_avg_age\")\n",
    ")\n",
    "\n",
    "print(\"✅ Gold tables written successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "072fc4a4-ae93-41b2-a799-83a294756976",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dept_salary_df)\n",
    "display(dept_country_count_df)\n",
    "display(dept_country_df)\n",
    "display(avg_age_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "employee_silver_to_gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
